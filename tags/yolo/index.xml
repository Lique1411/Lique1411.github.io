<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Yolo on Serein</title><link>https://Lique1411.github.io/tags/yolo/</link><description>Recent content in Yolo on Serein</description><generator>Hugo -- gohugo.io</generator><language>en</language><lastBuildDate>Sat, 30 Nov 2024 15:00:00 +0800</lastBuildDate><atom:link href="https://Lique1411.github.io/tags/yolo/index.xml" rel="self" type="application/rss+xml"/><item><title>yolo学习记录0</title><link>https://Lique1411.github.io/p/yolo%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%950/</link><pubDate>Sat, 30 Nov 2024 15:00:00 +0800</pubDate><guid>https://Lique1411.github.io/p/yolo%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%950/</guid><description>&lt;p>本文记录学习yolov11网络结构&lt;br>
1.需要掌握什么内容？&lt;br>
2.需要掌握到什么程度？&lt;br>
3.自检掌握程度&lt;br>&lt;/p>
&lt;h2 id="github开源仓库中yolov11相关内容">Github开源仓库中yolov11相关内容
&lt;/h2>&lt;h3 id="代码结构分析">代码结构分析
&lt;/h3>&lt;p>在ultralytics仓库中，网络结构相关的核心目录：&lt;br>&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;span class="lnt">4
&lt;/span>&lt;span class="lnt">5
&lt;/span>&lt;span class="lnt">6
&lt;/span>&lt;span class="lnt">7
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">ultralytics/
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">├── models/ # 模型定义
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">├── nn/ # 网络组件
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">│ ├── modules/ # 基础模块
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">│ └── tasks/ # 不同任务的实现
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">└── cfg/ # 配置文件
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> └── models/ # 模型配置
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;h3 id="网络架构组成">网络架构组成
&lt;/h3>&lt;p>从配置文件 ultralytics/cfg/models/11/yolo11.yaml&lt;br>
可以看到，整个网络分为三个主要部分：&lt;br>
1.Backbone (主干网络)&lt;br>
2.Neck (颈部网络)&lt;br>
3.Head (检测头)&lt;br>&lt;/p>
&lt;h2 id="需要掌握的内容">需要掌握的内容
&lt;/h2>&lt;p>1.了解特征提取的层次性&lt;br>
2.理解下采样的作用&lt;br>
3.知道感受野的概念&lt;br>
4.理解多尺度特征融合的重要性&lt;br>
5.了解特征金字塔网络(FPN)的原理&lt;br>
6.知道为什么需要特征增强&lt;br>
7.理解预测头的输出格式&lt;br>
8.了解分类和回归的区别&lt;br>
9.知道如何解析预测结果&lt;br>&lt;/p>
&lt;h2 id="掌握程度">掌握程度
&lt;/h2>&lt;p>1.能说出三个组件的基本功能&lt;br>
2.理解特征提取的概念&lt;br>
3.知道基本的网络结构&lt;br>&lt;/p>
&lt;p>4.能解释各组件之间的联系&lt;br>
5.理解特征融合的必要性&lt;br>
6.能分析网络的创新点&lt;br>&lt;/p>
&lt;p>7.能修改网络结构&lt;br>
8.能针对具体任务优化网络&lt;br>
9.理解性能和效率的平衡&lt;br>&lt;/p>
&lt;h2 id="自测问题">自测问题
&lt;/h2>&lt;p>问题1：为什么主干网络要逐步降低特征图尺寸？&lt;br>
问题2：颈部网络为什么需要双向特征融合？&lt;br>
问题3：检测头如何处理不同尺度的预测？&lt;br>&lt;/p>
&lt;p>尝试修改backbone结构，观察效果&lt;br>
观察不同层的特征图输出&lt;br>&lt;/p>
&lt;p>练习2：分析网络在不同场景的表现&lt;br>
理解预测结果的差异&lt;br>&lt;/p>
&lt;p>如何优化网络结构以提高特定目标的检测效果？&lt;br>
在资源受限情况下如何平衡性能和效率？&lt;br>
不同组件对最终性能的影响程度如何？&lt;br>&lt;/p></description></item><item><title>yolo学习记录1</title><link>https://Lique1411.github.io/p/yolo%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%951/</link><pubDate>Fri, 29 Nov 2024 15:00:00 +0800</pubDate><guid>https://Lique1411.github.io/p/yolo%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%951/</guid><description>&lt;p>学习yolov11的一些基本概念，和一些基础操作内容的作用&lt;/p>
&lt;h1 id="配置文件">配置文件
&lt;/h1>&lt;p>在yolov11下载的工具包中，&amp;ldquo;ultralytics-main\ultralytics\cfg\models\11\yolo11.yaml&amp;rdquo;&lt;br>
该文件中包括了yolov11的配置文件&lt;/p>
&lt;h2 id="相关概念">相关概念
&lt;/h2>&lt;h3 id="空间注意力">&lt;font color=green size=4>空间注意力&lt;/font>&lt;br>
&lt;/h3>&lt;h4 id="为什么要计算空间注意力">为什么要计算空间注意力
&lt;/h4>&lt;ul>
&lt;li>帮助模型聚焦于重要区域&lt;/li>
&lt;li>抑制无关背景的干扰&lt;/li>
&lt;li>增强特征的表达能力&lt;/li>
&lt;li>提高检测精度&lt;br>&lt;/li>
&lt;/ul>
&lt;h4 id="如何计算空间注意力">如何计算空间注意力
&lt;/h4>&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt"> 1
&lt;/span>&lt;span class="lnt"> 2
&lt;/span>&lt;span class="lnt"> 3
&lt;/span>&lt;span class="lnt"> 4
&lt;/span>&lt;span class="lnt"> 5
&lt;/span>&lt;span class="lnt"> 6
&lt;/span>&lt;span class="lnt"> 7
&lt;/span>&lt;span class="lnt"> 8
&lt;/span>&lt;span class="lnt"> 9
&lt;/span>&lt;span class="lnt">10
&lt;/span>&lt;span class="lnt">11
&lt;/span>&lt;span class="lnt">12
&lt;/span>&lt;span class="lnt">13
&lt;/span>&lt;span class="lnt">14
&lt;/span>&lt;span class="lnt">15
&lt;/span>&lt;span class="lnt">16
&lt;/span>&lt;span class="lnt">17
&lt;/span>&lt;span class="lnt">18
&lt;/span>&lt;span class="lnt">19
&lt;/span>&lt;span class="lnt">20
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-python" data-lang="python">&lt;span class="line">&lt;span class="cl">&lt;span class="k">class&lt;/span> &lt;span class="nc">SpatialAttention&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">nn&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">Module&lt;/span>&lt;span class="p">):&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">def&lt;/span> &lt;span class="fm">__init__&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="bp">self&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">kernel_size&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="mi">7&lt;/span>&lt;span class="p">):&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="nb">super&lt;/span>&lt;span class="p">()&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="fm">__init__&lt;/span>&lt;span class="p">()&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">padding&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="mi">3&lt;/span> &lt;span class="k">if&lt;/span> &lt;span class="n">kernel_size&lt;/span> &lt;span class="o">==&lt;/span> &lt;span class="mi">7&lt;/span> &lt;span class="k">else&lt;/span> &lt;span class="mi">1&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="bp">self&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">cv1&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">nn&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">Conv2d&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="mi">2&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">1&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">kernel_size&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">padding&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="n">padding&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">bias&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="kc">False&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="bp">self&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">act&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">nn&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">Sigmoid&lt;/span>&lt;span class="p">()&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">def&lt;/span> &lt;span class="nf">forward&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="bp">self&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">x&lt;/span>&lt;span class="p">):&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="c1"># 1. 计算通道维度的平均值和最大值&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">avg_out&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">torch&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">mean&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">x&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">1&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">keepdim&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="kc">True&lt;/span>&lt;span class="p">)&lt;/span> &lt;span class="c1"># 平均池化&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">max_out&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">_&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">torch&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">max&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">x&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">1&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">keepdim&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="kc">True&lt;/span>&lt;span class="p">)&lt;/span> &lt;span class="c1"># 最大池化&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="c1"># 2. 拼接这两个特征图&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">x_cat&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">torch&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">cat&lt;/span>&lt;span class="p">([&lt;/span>&lt;span class="n">avg_out&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">max_out&lt;/span>&lt;span class="p">],&lt;/span> &lt;span class="mi">1&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="c1"># 3. 通过卷积层和sigmoid得到注意力权重&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">attention&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="bp">self&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">act&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="bp">self&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">cv1&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">x_cat&lt;/span>&lt;span class="p">))&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="c1"># 4. 将注意力权重与原始特征相乘&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">return&lt;/span> &lt;span class="n">x&lt;/span> &lt;span class="o">*&lt;/span> &lt;span class="n">attention&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>计算步骤：&lt;br>
1.特征统计：&lt;/p>
&lt;ul>
&lt;li>计算特征图的通道平均值&lt;/li>
&lt;li>计算特征图的通道最大值&lt;br>&lt;/li>
&lt;/ul>
&lt;p>2.特征融合：&lt;/p>
&lt;ul>
&lt;li>将平均值和最大值特征图拼接&lt;/li>
&lt;li>得到表达空间信息的特征图&lt;br>&lt;/li>
&lt;/ul>
&lt;p>3.注意力权重：&lt;/p>
&lt;ul>
&lt;li>用7×7卷积处理融合特征&lt;/li>
&lt;li>通过sigmoid得到0-1之间的权重&lt;br>&lt;/li>
&lt;/ul>
&lt;p>4.特征增强：&lt;/p>
&lt;ul>
&lt;li>将注意力权重与原始特征相乘&lt;/li>
&lt;li>突出重要区域，抑制次要区域&lt;br>&lt;/li>
&lt;/ul>
&lt;h4 id="作用">作用
&lt;/h4>&lt;p>让网络能够：&lt;br>&lt;/p>
&lt;ul>
&lt;li>自适应地关注重要空间位置&lt;/li>
&lt;li>减少背景噪声的影响&lt;/li>
&lt;li>提高特征的判别能力&lt;/li>
&lt;/ul>
&lt;h3 id="自注意力">&lt;font color=green size=4>自注意力&lt;/font>&lt;br>
&lt;/h3>&lt;h4 id="为什么要计算自注意力">为什么要计算自注意力
&lt;/h4>&lt;p>1.1捕获长距离依赖关系&lt;br>
举个例子：&lt;br>&lt;/p>
&lt;ul>
&lt;li>检测人脸时，需要同时看到眼睛、鼻子、嘴巴等特征&lt;/li>
&lt;li>传统卷积只能看到局部区域&lt;/li>
&lt;li>自注意力可以直接建立任意两个位置的关联&lt;br>&lt;/li>
&lt;/ul>
&lt;p>1.2自适应特征提取&lt;br>
比如检测一只猫：&lt;br>
传统卷积：固定的感受野大小&lt;br>
自注意力：&lt;br>&lt;/p>
&lt;ul>
&lt;li>可以关注猫的整体轮廓&lt;/li>
&lt;li>也可以关注细节特征(如耳朵、胡须)&lt;/li>
&lt;li>注意力权重会自动调整&lt;br>&lt;/li>
&lt;/ul>
&lt;p>1.3上下文理解能力&lt;br>&lt;/p>
&lt;ul>
&lt;li>每个位置都能获取全局信息&lt;/li>
&lt;li>特征之间可以互相交互&lt;/li>
&lt;li>增强了对场景的理解&lt;br>&lt;/li>
&lt;/ul>
&lt;p>1.4动态权重分配&lt;br>&lt;/p>
&lt;ul>
&lt;li>自动学习重要特征的权重&lt;/li>
&lt;li>抑制无关背景的干扰&lt;/li>
&lt;li>提高特征的判别能力&lt;br>&lt;/li>
&lt;/ul>
&lt;p>1.5并行计算效率&lt;br>&lt;/p>
&lt;ul>
&lt;li>可以并行计算多个头&lt;/li>
&lt;li>每个头关注不同的特征模式&lt;/li>
&lt;li>提高了特征提取的多样性&lt;/li>
&lt;/ul>
&lt;h3 id="shortcut-连接">&lt;font color=green size=4>Shortcut 连接&lt;/font>&lt;br>
&lt;/h3>&lt;p>shortcut 连接是一种网络设计技巧，主要有以下特点：&lt;/p>
&lt;h4 id="基本原理">基本原理
&lt;/h4>&lt;ul>
&lt;li>在网络中创建一条捷径&lt;/li>
&lt;li>让信息可以跳过某些层直接传递&lt;/li>
&lt;li>类似于高速公路的快车道&lt;br>&lt;/li>
&lt;/ul>
&lt;h4 id="作用-1">作用&lt;br>
&lt;/h4>&lt;p>2.1 解决梯度消失问题&lt;/p>
&lt;ul>
&lt;li>深层网络训练困难&lt;/li>
&lt;li>shortcut 提供梯度反向传播的快速通道&lt;/li>
&lt;li>帮助深层网络也能有效训练&lt;br>&lt;/li>
&lt;/ul>
&lt;p>2.2 保留原始信息&lt;/p>
&lt;ul>
&lt;li>让网络可以直接访问浅层特征&lt;/li>
&lt;li>避免信息在传递过程中损失&lt;/li>
&lt;li>提高特征利用效率&lt;br>&lt;/li>
&lt;/ul>
&lt;h4 id="提升模型性能">提升模型性能
&lt;/h4>&lt;ul>
&lt;li>加快收敛速度&lt;/li>
&lt;li>提高特征提取能力&lt;/li>
&lt;li>改善最终检测效果&lt;/li>
&lt;/ul>
&lt;h2 id="主干网络">主干网络
&lt;/h2>&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt"> 1
&lt;/span>&lt;span class="lnt"> 2
&lt;/span>&lt;span class="lnt"> 3
&lt;/span>&lt;span class="lnt"> 4
&lt;/span>&lt;span class="lnt"> 5
&lt;/span>&lt;span class="lnt"> 6
&lt;/span>&lt;span class="lnt"> 7
&lt;/span>&lt;span class="lnt"> 8
&lt;/span>&lt;span class="lnt"> 9
&lt;/span>&lt;span class="lnt">10
&lt;/span>&lt;span class="lnt">11
&lt;/span>&lt;span class="lnt">12
&lt;/span>&lt;span class="lnt">13
&lt;/span>&lt;span class="lnt">14
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-python" data-lang="python">&lt;span class="line">&lt;span class="cl">&lt;span class="c1"># YOLO11n backbone&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">backbone&lt;/span>&lt;span class="p">:&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="c1"># [from, repeats, module, args]&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="o">-&lt;/span> &lt;span class="p">[&lt;/span>&lt;span class="o">-&lt;/span>&lt;span class="mi">1&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">1&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">Conv&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="p">[&lt;/span>&lt;span class="mi">64&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">3&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">2&lt;/span>&lt;span class="p">]]&lt;/span> &lt;span class="c1"># 0-P1/2&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="o">-&lt;/span> &lt;span class="p">[&lt;/span>&lt;span class="o">-&lt;/span>&lt;span class="mi">1&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">1&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">Conv&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="p">[&lt;/span>&lt;span class="mi">128&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">3&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">2&lt;/span>&lt;span class="p">]]&lt;/span> &lt;span class="c1"># 1-P2/4&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="o">-&lt;/span> &lt;span class="p">[&lt;/span>&lt;span class="o">-&lt;/span>&lt;span class="mi">1&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">2&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">C3k2&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="p">[&lt;/span>&lt;span class="mi">256&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="kc">False&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mf">0.25&lt;/span>&lt;span class="p">]]&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="o">-&lt;/span> &lt;span class="p">[&lt;/span>&lt;span class="o">-&lt;/span>&lt;span class="mi">1&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">1&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">Conv&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="p">[&lt;/span>&lt;span class="mi">256&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">3&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">2&lt;/span>&lt;span class="p">]]&lt;/span> &lt;span class="c1"># 3-P3/8&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="o">-&lt;/span> &lt;span class="p">[&lt;/span>&lt;span class="o">-&lt;/span>&lt;span class="mi">1&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">2&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">C3k2&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="p">[&lt;/span>&lt;span class="mi">512&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="kc">False&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mf">0.25&lt;/span>&lt;span class="p">]]&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="o">-&lt;/span> &lt;span class="p">[&lt;/span>&lt;span class="o">-&lt;/span>&lt;span class="mi">1&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">1&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">Conv&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="p">[&lt;/span>&lt;span class="mi">512&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">3&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">2&lt;/span>&lt;span class="p">]]&lt;/span> &lt;span class="c1"># 5-P4/16&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="o">-&lt;/span> &lt;span class="p">[&lt;/span>&lt;span class="o">-&lt;/span>&lt;span class="mi">1&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">2&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">C3k2&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="p">[&lt;/span>&lt;span class="mi">512&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="kc">True&lt;/span>&lt;span class="p">]]&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="o">-&lt;/span> &lt;span class="p">[&lt;/span>&lt;span class="o">-&lt;/span>&lt;span class="mi">1&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">1&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">Conv&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="p">[&lt;/span>&lt;span class="mi">1024&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">3&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">2&lt;/span>&lt;span class="p">]]&lt;/span> &lt;span class="c1"># 7-P5/32&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="o">-&lt;/span> &lt;span class="p">[&lt;/span>&lt;span class="o">-&lt;/span>&lt;span class="mi">1&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">2&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">C3k2&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="p">[&lt;/span>&lt;span class="mi">1024&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="kc">True&lt;/span>&lt;span class="p">]]&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="o">-&lt;/span> &lt;span class="p">[&lt;/span>&lt;span class="o">-&lt;/span>&lt;span class="mi">1&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">1&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">SPPF&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="p">[&lt;/span>&lt;span class="mi">1024&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">5&lt;/span>&lt;span class="p">]]&lt;/span> &lt;span class="c1"># 9&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="o">-&lt;/span> &lt;span class="p">[&lt;/span>&lt;span class="o">-&lt;/span>&lt;span class="mi">1&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">2&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">C2PSA&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="p">[&lt;/span>&lt;span class="mi">1024&lt;/span>&lt;span class="p">]]&lt;/span> &lt;span class="c1"># 10&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;ul>
&lt;li>[-1, 2, C3k2, [256, False, 0.25]]&lt;/li>
&lt;/ul>
&lt;p>这四个参数的含义：&lt;/p>
&lt;ol>
&lt;li>-1：表示输入来源&lt;/li>
&lt;/ol>
&lt;ul>
&lt;li>-1 表示使用上一层的输出作为输入&lt;/li>
&lt;li>如果是其他数字(如6)，则表示使用第6层的输出作为输入&lt;/li>
&lt;li>这种设计允许网络创建跳跃连接&lt;/li>
&lt;/ul>
&lt;ol start="2">
&lt;li>2：表示重复次数&lt;/li>
&lt;/ol>
&lt;ul>
&lt;li>这个模块会重复执行2次&lt;/li>
&lt;li>每次执行都会使用前一次的输出作为输入&lt;/li>
&lt;li>增加网络深度和特征提取能力&lt;/li>
&lt;/ul>
&lt;ol start="3">
&lt;li>C3k2：模块名称&lt;/li>
&lt;/ol>
&lt;ul>
&lt;li>表示使用C3k2模块（一种改进的CSP模块）&lt;/li>
&lt;/ul>
&lt;ol start="4">
&lt;li>[256, False, 0.25]：模块参数&lt;/li>
&lt;/ol>
&lt;p>可见主干网络包括以下关键组件：
1.初始卷积层
2.特征提取层&lt;/p>
&lt;h3 id="1初始卷积层">1.初始卷积层
&lt;/h3>&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-python" data-lang="python">&lt;span class="line">&lt;span class="cl"> &lt;span class="o">-&lt;/span> &lt;span class="p">[&lt;/span>&lt;span class="o">-&lt;/span>&lt;span class="mi">1&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">1&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">Conv&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="p">[&lt;/span>&lt;span class="mi">64&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">3&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">2&lt;/span>&lt;span class="p">]]&lt;/span> &lt;span class="c1"># 0-P1/2&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="o">-&lt;/span> &lt;span class="p">[&lt;/span>&lt;span class="o">-&lt;/span>&lt;span class="mi">1&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">1&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">Conv&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="p">[&lt;/span>&lt;span class="mi">128&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">3&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">2&lt;/span>&lt;span class="p">]]&lt;/span> &lt;span class="c1"># 1-P2/4&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>第一层卷积：Conv, [64, 3, 2]&lt;br>
输入：原始图像 (3通道)&lt;br>
输出：64通道特征图&lt;br>
卷积核：3×3&lt;br>
步长：2&lt;br>&lt;/p>
&lt;p>第二层卷积：Conv, [128, 3, 2]&lt;br>
输入：64通道特征图&lt;br>
输出：128通道特征图&lt;br>
卷积核：3×3&lt;br>
步长：2&lt;br>
&lt;font color=red size=4>步长2实现降采样&lt;/font>&lt;br>&lt;/p>
&lt;p>&lt;font color=red size=4>通道数增加扩展特征维度&lt;/font>&lt;br>&lt;/p>
&lt;ul>
&lt;li>通道数增加的意义&lt;/li>
&lt;li>每个通道代表一种特征模式&lt;/li>
&lt;li>更多通道 = 可以学习更多种类的特征&lt;/li>
&lt;li>类比：用64/128支画笔来画画，画笔越多，可以表达的细节越丰富&lt;/li>
&lt;/ul>
&lt;p>主要作用&lt;br>
1.降采样&lt;/p>
&lt;ul>
&lt;li>每层步长为2，两层共降采样4倍&lt;/li>
&lt;li>640×640 → 320×320 → 160×160&lt;/li>
&lt;li>减少后续计算量&lt;br>&lt;/li>
&lt;/ul>
&lt;p>2.特征提取&lt;br>&lt;/p>
&lt;ul>
&lt;li>提取基础的视觉特征（如边缘、纹理等）&lt;/li>
&lt;li>通道数增加：3 → 64 → 128&lt;/li>
&lt;li>增加特征表达能力&lt;br>&lt;/li>
&lt;/ul>
&lt;p>3.信息压缩&lt;br>&lt;/p>
&lt;ul>
&lt;li>压缩空间维度&lt;/li>
&lt;li>扩展通道维度&lt;/li>
&lt;li>为后续深层特征提取做准备&lt;/li>
&lt;/ul>
&lt;h3 id="2特征提取层">2.特征提取层
&lt;/h3>&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;span class="lnt">4
&lt;/span>&lt;span class="lnt">5
&lt;/span>&lt;span class="lnt">6
&lt;/span>&lt;span class="lnt">7
&lt;/span>&lt;span class="lnt">8
&lt;/span>&lt;span class="lnt">9
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-python" data-lang="python">&lt;span class="line">&lt;span class="cl"> &lt;span class="o">-&lt;/span> &lt;span class="p">[&lt;/span>&lt;span class="o">-&lt;/span>&lt;span class="mi">1&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">2&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">C3k2&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="p">[&lt;/span>&lt;span class="mi">256&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="kc">False&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mf">0.25&lt;/span>&lt;span class="p">]]&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="o">-&lt;/span> &lt;span class="p">[&lt;/span>&lt;span class="o">-&lt;/span>&lt;span class="mi">1&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">1&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">Conv&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="p">[&lt;/span>&lt;span class="mi">256&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">3&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">2&lt;/span>&lt;span class="p">]]&lt;/span> &lt;span class="c1"># 3-P3/8&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="o">-&lt;/span> &lt;span class="p">[&lt;/span>&lt;span class="o">-&lt;/span>&lt;span class="mi">1&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">2&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">C3k2&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="p">[&lt;/span>&lt;span class="mi">512&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="kc">False&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mf">0.25&lt;/span>&lt;span class="p">]]&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="o">-&lt;/span> &lt;span class="p">[&lt;/span>&lt;span class="o">-&lt;/span>&lt;span class="mi">1&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">1&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">Conv&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="p">[&lt;/span>&lt;span class="mi">512&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">3&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">2&lt;/span>&lt;span class="p">]]&lt;/span> &lt;span class="c1"># 5-P4/16&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="o">-&lt;/span> &lt;span class="p">[&lt;/span>&lt;span class="o">-&lt;/span>&lt;span class="mi">1&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">2&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">C3k2&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="p">[&lt;/span>&lt;span class="mi">512&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="kc">True&lt;/span>&lt;span class="p">]]&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="o">-&lt;/span> &lt;span class="p">[&lt;/span>&lt;span class="o">-&lt;/span>&lt;span class="mi">1&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">1&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">Conv&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="p">[&lt;/span>&lt;span class="mi">1024&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">3&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">2&lt;/span>&lt;span class="p">]]&lt;/span> &lt;span class="c1"># 7-P5/32&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="o">-&lt;/span> &lt;span class="p">[&lt;/span>&lt;span class="o">-&lt;/span>&lt;span class="mi">1&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">2&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">C3k2&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="p">[&lt;/span>&lt;span class="mi">1024&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="kc">True&lt;/span>&lt;span class="p">]]&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="o">-&lt;/span> &lt;span class="p">[&lt;/span>&lt;span class="o">-&lt;/span>&lt;span class="mi">1&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">1&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">SPPF&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="p">[&lt;/span>&lt;span class="mi">1024&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">5&lt;/span>&lt;span class="p">]]&lt;/span> &lt;span class="c1"># 9&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="o">-&lt;/span> &lt;span class="p">[&lt;/span>&lt;span class="o">-&lt;/span>&lt;span class="mi">1&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">2&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">C2PSA&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="p">[&lt;/span>&lt;span class="mi">1024&lt;/span>&lt;span class="p">]]&lt;/span> &lt;span class="c1"># 10&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>包含三个模块&lt;br>&lt;/p>
&lt;h4 id="c3k2-模块">&lt;font color=red size=4>C3k2 模块&lt;/font>
&lt;/h4>&lt;p>1.参数说明：&lt;/p>
&lt;ul>
&lt;li>[256, False, 0.25]：&lt;/li>
&lt;li>256：输出通道数&lt;/li>
&lt;li>False：是否使用 shortcut 连接&lt;/li>
&lt;li>0.25：通道压缩比例&lt;br>&lt;/li>
&lt;/ul>
&lt;p>2.工作原理：&lt;/p>
&lt;ul>
&lt;li>将输入特征分成两部分&lt;/li>
&lt;li>一部分直接通过&lt;/li>
&lt;li>另一部分经过多个卷积层处理&lt;/li>
&lt;li>最后合并两部分特征&lt;br>&lt;/li>
&lt;/ul>
&lt;p>3.优势：&lt;/p>
&lt;ul>
&lt;li>减少计算量&lt;/li>
&lt;li>保持梯度流动&lt;/li>
&lt;li>增强特征提取能力&lt;br>&lt;/li>
&lt;/ul>
&lt;h4 id="sppf-模块">&lt;font color=red size=4>SPPF 模块&lt;/font>
&lt;/h4>&lt;p>1.参数说明：&lt;/p>
&lt;ul>
&lt;li>[1024, 5]：&lt;/li>
&lt;li>1024：输出通道数&lt;/li>
&lt;li>5：最大池化核大小&lt;br>&lt;/li>
&lt;/ul>
&lt;p>2.工作原理：&lt;br>&lt;/p>
&lt;ul>
&lt;li>输入特征先经过 1×1 卷积降维&lt;/li>
&lt;li>连续进行最大池化，得到不同尺度特征&lt;/li>
&lt;li>将所有特征拼接&lt;/li>
&lt;li>最后用 1×1 卷积整合&lt;br>&lt;/li>
&lt;/ul>
&lt;p>3.优势：&lt;br>&lt;/p>
&lt;ul>
&lt;li>获取多尺度上下文信息&lt;/li>
&lt;li>比传统 SPP 更快&lt;/li>
&lt;li>增大感受野&lt;/li>
&lt;/ul>
&lt;h5 id="模块作用">模块作用：
&lt;/h5>&lt;p>1.渐进式感受野扩大：&lt;br>&lt;/p>
&lt;ul>
&lt;li>第一次池化：小感受野，捕获局部特征&lt;/li>
&lt;li>第二次池化：中等感受野，捕获中等范围特征&lt;/li>
&lt;li>第三次池化：大感受野，捕获全局特征&lt;br>&lt;/li>
&lt;/ul>
&lt;p>2.计算效率更高：&lt;br>&lt;/p>
&lt;ul>
&lt;li>SPP：需要3个独立的池化分支&lt;/li>
&lt;li>SPPF：串行池化，复用计算结果&lt;br>&lt;/li>
&lt;/ul>
&lt;p>3.特征融合更完整：&lt;br>&lt;/p>
&lt;ul>
&lt;li>将不同感受野的特征concat&lt;/li>
&lt;li>通过1×1卷积整合多尺度信息&lt;br>&lt;/li>
&lt;/ul>
&lt;h4 id="c2psa-模块">&lt;font color=red size=4>C2PSA 模块&lt;/font>
&lt;/h4>&lt;p>1.参数说明：&lt;/p>
&lt;ul>
&lt;li>[1024]：输出通道数&lt;br>&lt;/li>
&lt;/ul>
&lt;p>2.工作原理：&lt;br>
2.1 空间注意力计算：&lt;br>&lt;/p>
&lt;ul>
&lt;li>生成空间注意力图&lt;/li>
&lt;li>突出重要区域&lt;/li>
&lt;li>抑制无关区域&lt;br>
2.2 特征增强&lt;br>&lt;/li>
&lt;li>原始特征与注意力图相乘&lt;/li>
&lt;li>增强重要特征&lt;/li>
&lt;li>抑制噪声特征&lt;br>&lt;/li>
&lt;/ul>
&lt;p>3.优势：&lt;br>&lt;/p>
&lt;ul>
&lt;li>自适应特征增强&lt;/li>
&lt;li>提高特征表达能力&lt;/li>
&lt;li>改善检测性能&lt;/li>
&lt;/ul>
&lt;h5 id="模块作用-1">模块作用
&lt;/h5>&lt;p>1.特征分离与处理：&lt;br>&lt;/p>
&lt;ul>
&lt;li>输入特征通过cv1分成两部分(a,b)&lt;/li>
&lt;li>a分支保持原始信息&lt;/li>
&lt;li>b分支经过PSA注意力处理&lt;/li>
&lt;li>最后将两部分特征重新融合&lt;br>&lt;/li>
&lt;/ul>
&lt;p>2.注意力增强：&lt;br>&lt;/p>
&lt;ul>
&lt;li>使用PSABlock进行注意力计算&lt;/li>
&lt;li>每个PSABlock包含self-attention机制&lt;/li>
&lt;li>通过多头注意力处理空间信息&lt;br>&lt;/li>
&lt;/ul></description></item></channel></rss>